{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWB2y7QNNKmmvC+XRQZvr6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZscMIgOVK4N"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","folder= \"/content/sample_data/Day Light Hours Data\"\n","# Iterate over years from 2018 to 2023\n","for year in range(2018, 2024):\n","    # URL to scrape\n","    url = f'https://aa.usno.navy.mil/calculated/durdaydark?year={year}&task=0&lat=27.1613&lon=84.6266&label=&tz=0.00&tz_sign=1&submit=Get+Data'\n","\n","    # Fetch the HTML content from the URL\n","    response = requests.get(url)\n","    response.raise_for_status()  # Check if the request was successful\n","\n","    # Parse the HTML content using BeautifulSoup\n","    soup = BeautifulSoup(response.content, 'html.parser')\n","\n","    # Find the table containing the data\n","    table = soup.find('table')\n","\n","    # Initialize a list to store the table data\n","    table_data = []\n","\n","    # Find all rows in the table body\n","    rows = soup.find_all('tr')\n","\n","    # Extract data from each row\n","    for row in rows:\n","        # Extract text from each cell in the row\n","        row_data = [cell.get_text(strip=True) for cell in row.find_all('td')]\n","        table_data.append(row_data)\n","\n","    # Write the scraped data to a CSV file\n","    with open(f'Mainatanr_daylight_{year}.csv', 'w', newline='') as csvfile:\n","        writer = csv.writer(csvfile)\n","        writer.writerows(table_data)\n","\n","    print(f\"Data for {year} has been written to Mainatanr_daylight_{year}.csv\")"]}]}